{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9sg86ybxfYCM",
        "outputId": "8ddca592-655e-4a98-a977-b5408e04aa52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-9cgjep6z\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-9cgjep6z\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 28f872a2f99a1b201bcd0db14fdbc5a496b9bfd7\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "The nvcc4jupyter extension is already loaded. To reload it, use:\n",
            "  %reload_ext nvcc4jupyter\n"
          ]
        }
      ],
      "source": [
        "# Load the extension that allows us to compile CUDA code in python notebooks\n",
        "# Documentation is here: https://nvcc4jupyter.readthedocs.io/en/latest/\n",
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
        "%load_ext nvcc4jupyter\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgUFIYVolT5O"
      },
      "source": [
        "# 新段落"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_Ca_dytlrnY",
        "outputId": "dd6b9f4e-9082-45ff-ddc6-a8914d9c166f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MNIST dataset downloaded successfully.\n"
          ]
        }
      ],
      "source": [
        "import torchvision\n",
        "import os\n",
        "\n",
        "def download_mnist_dataset():\n",
        "    # 创建目录\n",
        "    os.makedirs(\"train_mnist/MNIST/raw\", exist_ok=True)\n",
        "    os.makedirs(\"test_mnist/MNIST/raw\", exist_ok=True)\n",
        "\n",
        "    # 下载训练数据\n",
        "    train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True)\n",
        "    test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True)\n",
        "\n",
        "    print(\"MNIST dataset downloaded successfully.\")\n",
        "\n",
        "# 调用函数下载数据集\n",
        "download_mnist_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-X3xtiKKRV6i",
        "outputId": "c66599b7-5c22-440b-d1dc-f0d03f7aa4a4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'DO NOT UNCOMMENT THIS CELL unless you are running this notebook on Google Colab'"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''DO NOT UNCOMMENT THIS CELL unless you are running this notebook on Google Colab'''\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive/', force_remount=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "yg7P0ezLfcos"
      },
      "outputs": [],
      "source": [
        "%%cuda_group_save -g \"knn\" -n \"main.cu\"\n",
        "\n",
        "// Required header files\n",
        "#include <iostream>\n",
        "#include <fstream>\n",
        "#include <vector>\n",
        "#include <string>\n",
        "#include <cstring>\n",
        "#include <algorithm>\n",
        "#include <cuda_runtime.h>\n",
        "#include <cfloat>\n",
        "#include <chrono>\n",
        "\n",
        "// Constants definition\n",
        "#define THREADS 256\n",
        "#define IMAGESIZE 784\n",
        "\n",
        "// Error checking macro\n",
        "#define CUDA_CHECK(call) { \\\n",
        "    cudaError_t err = call; \\\n",
        "    if (err != cudaSuccess) { \\\n",
        "        printf(\"CUDA error %d: %s at %s:%d\\n\", err, cudaGetErrorString(err), __FILE__, __LINE__); \\\n",
        "        exit(1); \\\n",
        "    } \\\n",
        "}\n",
        "\n",
        "struct TrainingSample {\n",
        "    int label;\n",
        "    float image[IMAGESIZE];\n",
        "};\n",
        "\n",
        "uint32_t swap32(uint32_t val) {\n",
        "    val = ((val << 8) & 0xFF00FF00) | ((val >> 8) & 0xFF00FF);\n",
        "    return (val << 16) | (val >> 16);\n",
        "}\n",
        "\n",
        "__global__ void bitonicSortStep(float* d_distances, int* d_labels, int j, int k, int num_samples) {\n",
        "    unsigned int i = threadIdx.x + blockDim.x * blockIdx.x;\n",
        "    if (i >= num_samples) return;\n",
        "\n",
        "    unsigned int ixj = i ^ j;\n",
        "    if (ixj > i && ixj < num_samples) {\n",
        "        if ((i & k) == 0) {\n",
        "            if (d_distances[i] > d_distances[ixj]) {\n",
        "                float temp_dist = d_distances[i];\n",
        "                d_distances[i] = d_distances[ixj];\n",
        "                d_distances[ixj] = temp_dist;\n",
        "\n",
        "                int temp_label = d_labels[i];\n",
        "                d_labels[i] = d_labels[ixj];\n",
        "                d_labels[ixj] = temp_label;\n",
        "            }\n",
        "        } else {\n",
        "            if (d_distances[i] < d_distances[ixj]) {\n",
        "                float temp_dist = d_distances[i];\n",
        "                d_distances[i] = d_distances[ixj];\n",
        "                d_distances[ixj] = temp_dist;\n",
        "\n",
        "                int temp_label = d_labels[i];\n",
        "                d_labels[i] = d_labels[ixj];\n",
        "                d_labels[ixj] = temp_label;\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "void bitonicSort(float* d_distances, int* d_labels, int num_samples, cudaStream_t stream) {\n",
        "    int pow2_size = 1;\n",
        "    while (pow2_size < num_samples) pow2_size <<= 1;\n",
        "\n",
        "    dim3 block(256);  // Fixed thread block size\n",
        "    dim3 grid((pow2_size + block.x - 1) / block.x);  // Calculate grid size\n",
        "\n",
        "    // Main sorting loops\n",
        "    for (int k = 2; k <= pow2_size; k <<= 1) {\n",
        "        for (int j = k >> 1; j > 0; j >>= 1) {\n",
        "            bitonicSortStep<<<grid, block, 0, stream>>>(\n",
        "                d_distances, d_labels, j, k, num_samples\n",
        "            );\n",
        "            CUDA_CHECK(cudaGetLastError());\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void computeDistances(float* d_images, float* d_testImage,\n",
        "                               float* d_distances, int* d_labels,\n",
        "                               int* d_train_labels, int num_samples) {\n",
        "    int tid = threadIdx.x;\n",
        "    int bid = blockIdx.x;\n",
        "    int idx = bid * blockDim.x + tid;\n",
        "    \n",
        "    if (idx < num_samples) {\n",
        "        float sum = 0.0f;\n",
        "        \n",
        "        // 使用向量化加载优化计算\n",
        "        float4* train_vec = (float4*)(&d_images[idx * IMAGESIZE]);\n",
        "        float4* test_vec = (float4*)d_testImage;\n",
        "        \n",
        "        // IMAGESIZE = 784 = 196 * 4 向量化处理前784个元素\n",
        "        #pragma unroll 8\n",
        "        for (int i = 0; i < IMAGESIZE/4; i++) {\n",
        "            float4 train = train_vec[i];\n",
        "            float4 test = test_vec[i];\n",
        "            \n",
        "            float diff_x = train.x - test.x;\n",
        "            float diff_y = train.y - test.y;\n",
        "            float diff_z = train.z - test.z;\n",
        "            float diff_w = train.w - test.w;\n",
        "            \n",
        "            sum += diff_x * diff_x + diff_y * diff_y + \n",
        "                   diff_z * diff_z + diff_w * diff_w;\n",
        "        }\n",
        "        \n",
        "        // 处理剩余的元素\n",
        "        for (int i = (IMAGESIZE/4)*4; i < IMAGESIZE; i++) {\n",
        "            float diff = d_images[idx * IMAGESIZE + i] - d_testImage[i];\n",
        "            sum += diff * diff;\n",
        "        }\n",
        "        \n",
        "        d_distances[idx] = sqrtf(sum);\n",
        "        d_labels[idx] = d_train_labels[idx];\n",
        "    }\n",
        "}\n",
        "\n",
        "bool loadMNISTImages(const std::string& image_path, const std::string& label_path,\n",
        "                    std::vector<TrainingSample>& samples) {\n",
        "    std::ifstream image_file(image_path, std::ios::binary);\n",
        "    if (!image_file) {\n",
        "        std::cerr << \"Cannot open image file: \" << image_path << std::endl;\n",
        "        return false;\n",
        "    }\n",
        "\n",
        "    std::ifstream label_file(label_path, std::ios::binary);\n",
        "    if (!label_file) {\n",
        "        std::cerr << \"Cannot open label file: \" << label_path << std::endl;\n",
        "        return false;\n",
        "    }\n",
        "\n",
        "    uint32_t magic, num_items, num_rows, num_cols;\n",
        "    image_file.read(reinterpret_cast<char*>(&magic), sizeof(magic));\n",
        "    image_file.read(reinterpret_cast<char*>(&num_items), sizeof(num_items));\n",
        "    image_file.read(reinterpret_cast<char*>(&num_rows), sizeof(num_rows));\n",
        "    image_file.read(reinterpret_cast<char*>(&num_cols), sizeof(num_cols));\n",
        "\n",
        "    magic = swap32(magic);\n",
        "    num_items = swap32(num_items);\n",
        "    num_rows = swap32(num_rows);\n",
        "    num_cols = swap32(num_cols);\n",
        "\n",
        "    uint32_t label_magic, num_labels;\n",
        "    label_file.read(reinterpret_cast<char*>(&label_magic), sizeof(label_magic));\n",
        "    label_file.read(reinterpret_cast<char*>(&num_labels), sizeof(num_labels));\n",
        "\n",
        "    label_magic = swap32(label_magic);\n",
        "    num_labels = swap32(num_labels);\n",
        "\n",
        "    samples.resize(num_items);\n",
        "    std::vector<unsigned char> pixels(num_rows * num_cols);\n",
        "\n",
        "    for (uint32_t i = 0; i < num_items; ++i) {\n",
        "        unsigned char label;\n",
        "        label_file.read(reinterpret_cast<char*>(&label), 1);\n",
        "        samples[i].label = static_cast<int>(label);\n",
        "\n",
        "        image_file.read(reinterpret_cast<char*>(pixels.data()), pixels.size());\n",
        "\n",
        "        for (size_t j = 0; j < pixels.size(); ++j) {\n",
        "            samples[i].image[j] = static_cast<float>(pixels[j]) / 255.0f;\n",
        "        }\n",
        "\n",
        "        if (i % 1000 == 0) {\n",
        "            std::cout << \"\\rLoading data: \" << (i * 100.0f / num_items) << \"%\" << std::flush;\n",
        "        }\n",
        "    }\n",
        "    std::cout << \"\\rLoading data: 100%\" << std::endl;\n",
        "\n",
        "    return true;\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    // Start timing for performance measurement\n",
        "    // 开始计时，用于性能测量\n",
        "    auto start_time = std::chrono::high_resolution_clock::now();\n",
        "    \n",
        "    // Vectors to store training and test data\n",
        "    // 用于存储训练和测试数据的向量\n",
        "    std::vector<TrainingSample> train_samples;\n",
        "    std::vector<TrainingSample> test_samples;\n",
        "\n",
        "    // Load training data from MNIST dataset\n",
        "    // 从MNIST数据集加载训练数据\n",
        "    if (!loadMNISTImages(\"./data/MNIST/raw/train-images-idx3-ubyte\",\n",
        "                        \"./data/MNIST/raw/train-labels-idx1-ubyte\",\n",
        "                        train_samples)) {\n",
        "        return -1;\n",
        "    }\n",
        "    std::cout << \"Successfully loaded \" << train_samples.size() << \" training samples.\" << std::endl;\n",
        "\n",
        "    // Load test data from MNIST dataset\n",
        "    // 从MNIST数据集加载测试数据\n",
        "    if (!loadMNISTImages(\"./data/MNIST/raw/t10k-images-idx3-ubyte\",\n",
        "                        \"./data/MNIST/raw/t10k-labels-idx1-ubyte\",\n",
        "                        test_samples)) {\n",
        "        return -1;\n",
        "    }\n",
        "    std::cout << \"Successfully loaded \" << test_samples.size() << \" testing samples.\" << std::endl;\n",
        "\n",
        "    // Get the number of samples\n",
        "    // 获取样本数量\n",
        "    int num_trainsamples = train_samples.size();\n",
        "    int num_testsamples = test_samples.size();\n",
        "\n",
        "    // Allocate page-locked (pinned) memory for better transfer speed\n",
        "    // 分配页锁定内存（固定内存）以获得更好的传输速度\n",
        "    float* h_train_images;\n",
        "    int* h_train_labels;\n",
        "    CUDA_CHECK(cudaMallocHost(&h_train_images, num_trainsamples * IMAGESIZE * sizeof(float)));\n",
        "    CUDA_CHECK(cudaMallocHost(&h_train_labels, num_trainsamples * sizeof(int)));\n",
        "\n",
        "    // Copy data to page-locked memory\n",
        "    // 将数据复制到页锁定内存\n",
        "    for (int i = 0; i < num_trainsamples; ++i) {\n",
        "        h_train_labels[i] = train_samples[i].label;\n",
        "        std::memcpy(&h_train_images[i * IMAGESIZE], train_samples[i].image, IMAGESIZE * sizeof(float));\n",
        "    }\n",
        "\n",
        "    // Allocate GPU memory with proper alignment for vectorized access\n",
        "    // 分配GPU内存，确保向量化访问的正确对齐\n",
        "    float* d_train_images;\n",
        "    int* d_train_labels;\n",
        "    size_t pitch;  // Pitch for aligned memory allocation / 对齐内存分配的间距\n",
        "    CUDA_CHECK(cudaMallocPitch((void**)&d_train_images, &pitch,\n",
        "                              IMAGESIZE * sizeof(float), num_trainsamples));\n",
        "    CUDA_CHECK(cudaMalloc(&d_train_labels, num_trainsamples * sizeof(int)));\n",
        "\n",
        "    // Copy training data to GPU\n",
        "    // 将训练数据复制到GPU\n",
        "    CUDA_CHECK(cudaMemcpy(d_train_images, h_train_images, \n",
        "                         num_trainsamples * IMAGESIZE * sizeof(float), \n",
        "                         cudaMemcpyHostToDevice));\n",
        "    CUDA_CHECK(cudaMemcpy(d_train_labels, h_train_labels, \n",
        "                         num_trainsamples * sizeof(int), \n",
        "                         cudaMemcpyHostToDevice));\n",
        "\n",
        "    // KNN algorithm parameters\n",
        "    // KNN算法参数\n",
        "    const int k = 5;  // Number of nearest neighbors / 最近邻的数量\n",
        "    int correct_predictions = 0;  // Counter for correct predictions / 正确预测的计数器\n",
        "    \n",
        "    // Allocate GPU memory for test processing\n",
        "    // 为测试处理分配GPU内存\n",
        "    float* d_test_image;  // Current test image / 当前测试图像\n",
        "    float* d_distances;   // Distances to all training samples / 到所有训练样本的距离\n",
        "    int* d_sort_labels;   // Labels for sorting / 用于排序的标签\n",
        "    float* h_distances;   // Host memory for distances / 主机端的距离内存\n",
        "    int* h_labels;        // Host memory for labels / 主机端的标签内存\n",
        "    \n",
        "    // Ensure memory alignment for vectorized access\n",
        "    // 确保内存对齐以进行向量化访问\n",
        "    CUDA_CHECK(cudaMalloc(&d_test_image, ((IMAGESIZE + 3) / 4) * 4 * sizeof(float)));\n",
        "    CUDA_CHECK(cudaMalloc(&d_distances, num_trainsamples * sizeof(float)));\n",
        "    CUDA_CHECK(cudaMalloc(&d_sort_labels, num_trainsamples * sizeof(int)));\n",
        "    CUDA_CHECK(cudaMallocHost(&h_distances, k * sizeof(float)));\n",
        "    CUDA_CHECK(cudaMallocHost(&h_labels, k * sizeof(int)));\n",
        "\n",
        "    // Configure kernel execution parameters\n",
        "    // 配置核函数执行参数\n",
        "    const int threadsPerBlock = 256;  // Threads per block / 每个块的线程数\n",
        "    int blocksPerGrid = (num_trainsamples + threadsPerBlock - 1) / threadsPerBlock;  // Number of blocks / 块的数量\n",
        "\n",
        "    // Process each test sample\n",
        "    // 处理每个测试样本\n",
        "    for (int t = 0; t < num_testsamples; t++) {\n",
        "        // Copy current test image to GPU\n",
        "        // 将当前测试图像复制到GPU\n",
        "        CUDA_CHECK(cudaMemcpy(d_test_image, test_samples[t].image,\n",
        "                            IMAGESIZE * sizeof(float), cudaMemcpyHostToDevice));\n",
        "\n",
        "        // Compute distances between test image and all training images\n",
        "        // 计算测试图像与所有训练图像之间的距离\n",
        "        computeDistances<<<blocksPerGrid, threadsPerBlock>>>(\n",
        "            d_train_images,\n",
        "            d_test_image,\n",
        "            d_distances,\n",
        "            d_sort_labels,\n",
        "            d_train_labels,\n",
        "            num_trainsamples\n",
        "        );\n",
        "        CUDA_CHECK(cudaGetLastError());\n",
        "\n",
        "        // Sort distances to find k nearest neighbors\n",
        "        // 对距离进行排序以找到k个最近邻\n",
        "        bitonicSort(d_distances, d_sort_labels, num_trainsamples, 0);\n",
        "\n",
        "        // Copy k nearest neighbors back to host\n",
        "        // 将k个最近邻的结果复制回主机\n",
        "        CUDA_CHECK(cudaMemcpy(h_distances, d_distances, k * sizeof(float), cudaMemcpyDeviceToHost));\n",
        "        CUDA_CHECK(cudaMemcpy(h_labels, d_sort_labels, k * sizeof(int), cudaMemcpyDeviceToHost));\n",
        "\n",
        "        // Majority voting among k nearest neighbors\n",
        "        // k个最近邻中的多数投票\n",
        "        std::vector<int> labelCount(10, 0);  // Count votes for each digit / 统计每个数字的票数\n",
        "        for (int i = 0; i < k; ++i) {\n",
        "            if (h_labels[i] >= 0 && h_labels[i] < 10) {\n",
        "                labelCount[h_labels[i]]++;\n",
        "            }\n",
        "        }\n",
        "\n",
        "        // Find the label with most votes\n",
        "        // 找出得票最多的标签\n",
        "        int predicted_label = std::distance(labelCount.begin(),\n",
        "                                        std::max_element(labelCount.begin(), labelCount.end()));\n",
        "        int true_label = test_samples[t].label;\n",
        "\n",
        "        // Update accuracy statistics\n",
        "        // 更新准确率统计\n",
        "        if (predicted_label == true_label) {\n",
        "            correct_predictions++;\n",
        "        }\n",
        "\n",
        "        // Show progress every 100 samples\n",
        "        // 每处理100个样本显示一次进度\n",
        "        if (t % 100 == 0) {\n",
        "            float current_accuracy = (float)correct_predictions / (t + 1) * 100.0f;\n",
        "            std::cout << \"\\rProcessing: \" << t << \"/\" << num_testsamples\n",
        "                     << \" (Current Accuracy: \" << current_accuracy << \"%)\" << std::flush;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Calculate final results\n",
        "    // 计算最终结果\n",
        "    float accuracy = (float)correct_predictions / num_testsamples * 100.0f;\n",
        "    auto end_time = std::chrono::high_resolution_clock::now();\n",
        "    auto duration = std::chrono::duration_cast<std::chrono::milliseconds>(end_time - start_time);\n",
        "\n",
        "    // Print final results\n",
        "    // 打印最终结果\n",
        "    std::cout << \"\\n\\nFinal Results:\" << std::endl;\n",
        "    std::cout << \"Total test samples: \" << num_testsamples << std::endl;\n",
        "    std::cout << \"Correct predictions: \" << correct_predictions << std::endl;\n",
        "    std::cout << \"Accuracy: \" << accuracy << \"%\" << std::endl;\n",
        "    std::cout << \"Total execution time: \" << duration.count() / 1000.0 << \" seconds\" << std::endl;\n",
        "\n",
        "    // Cleanup allocated memory\n",
        "    // 清理分配的内存\n",
        "    CUDA_CHECK(cudaFree(d_test_image));\n",
        "    CUDA_CHECK(cudaFree(d_distances));\n",
        "    CUDA_CHECK(cudaFree(d_sort_labels));\n",
        "    CUDA_CHECK(cudaFreeHost(h_distances));\n",
        "    CUDA_CHECK(cudaFreeHost(h_labels));\n",
        "    CUDA_CHECK(cudaFreeHost(h_train_images));\n",
        "    CUDA_CHECK(cudaFreeHost(h_train_labels));\n",
        "    CUDA_CHECK(cudaFree(d_train_images));\n",
        "    CUDA_CHECK(cudaFree(d_train_labels));\n",
        "\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%cuda_group_run --group \"knn\" --compiler-args \"-O3 -g -std=c++20 -arch=sm_75\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
